{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                condition  row  column  \\\n",
      "0       b\"\\x10\\xf4\\x86!\\x07\\xdc\\xa8\\x96 \\x01\\x00+\\xd0\\...    5       8   \n",
      "1       b\"\\x0f9\\xc6\\x00\\x16\\x10\\x00Y@\\x01u\\x8f\\xb8\\x00...    2       9   \n",
      "2       b'\\x00\\x04\\x00\\x80\\x10\\x02K\\x00\\x08\\x01\\x00/\\x...    7       3   \n",
      "3       b'\\x00\\x05\\x84\\x80\\x12\\xdd7@\\x08\\x01T@\\x06H\\x9...    3       2   \n",
      "4       b'\\x0b\\x99\\xc6\\x00\\x10\\x02\\x00@\\x08\\x01\\x00 \\x...    1       5   \n",
      "...                                                   ...  ...     ...   \n",
      "486213  b\"\\x0f9\\xc6\\x00\\x16\\x10\\xa8\\x80\\x08\\x01u\\x8f\\x...    6       9   \n",
      "486214  b'\\x0f9\\xc64\\xa0\\x02\\x00[P\\x01u\\x8f\\xb8\\x00\\xa...    5       2   \n",
      "486215  b'\\x00\\x05\\xa5\\x00\\x16\\x10\\xa8\\x80\\x0bj\\x00 \\x...    9       2   \n",
      "486216  b'\\x00\\x05\\xc6\\x00\\x10\\x02\\x00@\\x08\\x01u\\x80\\x...    7       9   \n",
      "486217  b'\\x0b\\xd4\\x00\\x80\\x17\\xb7\\x0fI\\xc8\\xa9\\x00 \\x...    5       4   \n",
      "\n",
      "        pieceName  pieceID  \n",
      "0               3        4  \n",
      "1               1       22  \n",
      "2               5       28  \n",
      "3               7       20  \n",
      "4               0       21  \n",
      "...           ...      ...  \n",
      "486213          7       20  \n",
      "486214          1       22  \n",
      "486215         11       28  \n",
      "486216          7       16  \n",
      "486217          7       37  \n",
      "\n",
      "[486218 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "\n",
    "user = 'root'     # ユーザ名\n",
    "password = 'root' # パスワード\n",
    "host = 'localhost'    # ホスト名 or IP\n",
    "db = 'shogi'       # データベース\n",
    "port = 3306           # ポート\n",
    "\n",
    "url = f'mysql+pymysql://{user}:{password}@{host}:{port}/{db}?charset=utf8'\n",
    "\n",
    "# engine作成\n",
    "engine = sa.create_engine(url, echo=False)\n",
    "\n",
    "# pandasのread_sql関数にselect文とengineを指定する\n",
    "query = \"select p.`condition`, c.`row`, c.`column`, c.pieceName, c.pieceID from shogi.node as c join shogi.node as p on c.parentID = p.ID where p.`condition` is not null;\"\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                condition   row1   row2  \\\n",
      "0       b\"\\x10\\xf4\\x86!\\x07\\xdc\\xa8\\x96 \\x01\\x00+\\xd0\\...  False  False   \n",
      "1       b\"\\x0f9\\xc6\\x00\\x16\\x10\\x00Y@\\x01u\\x8f\\xb8\\x00...  False   True   \n",
      "2       b'\\x00\\x04\\x00\\x80\\x10\\x02K\\x00\\x08\\x01\\x00/\\x...  False  False   \n",
      "3       b'\\x00\\x05\\x84\\x80\\x12\\xdd7@\\x08\\x01T@\\x06H\\x9...  False  False   \n",
      "4       b'\\x0b\\x99\\xc6\\x00\\x10\\x02\\x00@\\x08\\x01\\x00 \\x...   True  False   \n",
      "...                                                   ...    ...    ...   \n",
      "486213  b\"\\x0f9\\xc6\\x00\\x16\\x10\\xa8\\x80\\x08\\x01u\\x8f\\x...  False  False   \n",
      "486214  b'\\x0f9\\xc64\\xa0\\x02\\x00[P\\x01u\\x8f\\xb8\\x00\\xa...  False  False   \n",
      "486215  b'\\x00\\x05\\xa5\\x00\\x16\\x10\\xa8\\x80\\x0bj\\x00 \\x...  False  False   \n",
      "486216  b'\\x00\\x05\\xc6\\x00\\x10\\x02\\x00@\\x08\\x01u\\x80\\x...  False  False   \n",
      "486217  b'\\x0b\\xd4\\x00\\x80\\x17\\xb7\\x0fI\\xc8\\xa9\\x00 \\x...  False  False   \n",
      "\n",
      "         row3   row4   row5   row6   row7   row8   row9  ...  pid37  pid38  \\\n",
      "0       False  False   True  False  False  False  False  ...  False  False   \n",
      "1       False  False  False  False  False  False  False  ...  False  False   \n",
      "2       False  False  False  False   True  False  False  ...  False  False   \n",
      "3        True  False  False  False  False  False  False  ...  False  False   \n",
      "4       False  False  False  False  False  False  False  ...  False  False   \n",
      "...       ...    ...    ...    ...    ...    ...    ...  ...    ...    ...   \n",
      "486213  False  False  False   True  False  False  False  ...  False  False   \n",
      "486214  False  False   True  False  False  False  False  ...  False  False   \n",
      "486215  False  False  False  False  False  False   True  ...  False  False   \n",
      "486216  False  False  False  False   True  False  False  ...  False  False   \n",
      "486217  False  False   True  False  False  False  False  ...   True  False   \n",
      "\n",
      "        pid39   pid4  pid40   pid5   pid6   pid7   pid8   pid9  \n",
      "0       False   True  False  False  False  False  False  False  \n",
      "1       False  False  False  False  False  False  False  False  \n",
      "2       False  False  False  False  False  False  False  False  \n",
      "3       False  False  False  False  False  False  False  False  \n",
      "4       False  False  False  False  False  False  False  False  \n",
      "...       ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "486213  False  False  False  False  False  False  False  False  \n",
      "486214  False  False  False  False  False  False  False  False  \n",
      "486215  False  False  False  False  False  False  False  False  \n",
      "486216  False  False  False  False  False  False  False  False  \n",
      "486217  False  False  False  False  False  False  False  False  \n",
      "\n",
      "[486218 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = df.copy()\n",
    "dataset['row'] = dataset['row'].map({1: 'row1', 2: 'row2', 3: 'row3', 4: 'row4', 5: 'row5', 6: 'row6', 7: 'row7', 8: 'row8', 9: 'row9'})\n",
    "dataset = pd.get_dummies(dataset, columns=['row'], prefix='', prefix_sep='')\n",
    "dataset['column'] = dataset['column'].map({1: 'cone', 2: 'column2', 3: 'column3', 4: 'column4', 5: 'column5', 6: 'column6', 7: 'column7', 8: 'column8', 9: 'column9'})\n",
    "dataset = pd.get_dummies(dataset, columns=['column'], prefix='', prefix_sep='')\n",
    "dataset['pieceName'] = dataset['pieceName'].map({-1: 'non', 0: 'king', 1: 'rook', 2: 'bichop', 3: 'goldgengral', 4: 'silvergeneral', 5: 'knight', 6: 'lance', 7: 'pawn', 8: 'promoted_rook', 9: 'promoted_bichop', 10: 'promoted_silvergeneral', 11: 'promoted_knight', 12: 'promoted_lance', 13: 'promoted_pawn'})\n",
    "dataset = pd.get_dummies(dataset, columns=['pieceName'], prefix='', prefix_sep='')\n",
    "pieceID = {}\n",
    "for i in range(41):\n",
    "    pieceID[i] = f\"pid{i}\"\n",
    "dataset['pieceID'] = dataset['pieceID'].map(pieceID)\n",
    "dataset = pd.get_dummies(dataset, columns=['pieceID'], prefix='', prefix_sep='')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=1341),\n",
    "    tf.keras.layers.Dense(1341, activation='relu'),\n",
    "    tf.keras.layers.Dense(72)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit()\n",
      "File \u001b[1;32mc:\\Users\\syuns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\syuns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1105\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1102\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m   1103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m   1104\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1106\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle input: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1107\u001b[0m             _type_name(x), _type_name(y)\n\u001b[0;32m   1108\u001b[0m         )\n\u001b[0;32m   1109\u001b[0m     )\n\u001b[0;32m   1110\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1111\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1113\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[0;32m   1115\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
